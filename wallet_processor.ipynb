{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# A JSON dataset is pointed to by path.\n",
    "# The path can be either a single text file or a directory storing text files"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path = \"wallets_test\"\n",
    "path = \"wallets\"\n",
    "wallets_df = spark.read.json(path)\n",
    "\n",
    "wallets = wallets_df.rdd.map(lambda w: w.asDict(True)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wallet_transactions = wallets.flatMap(lambda w:  [ (w['address'], tx) for tx in w['txs'] or [] ] ) \\\n",
    "                                .map(lambda w:  (w[0], (w[1].get('incoming'), w[1].get('outgoing'))  ))\n",
    "\n",
    "\n",
    "balance = wallets.map(lambda w: (w['address'], float(w['balance'] or 0)))\n",
    "received_value = wallets.map(lambda w: (w['address'], float(w['received_value'] or 0 )))\n",
    "total_txs = wallets.map(lambda w: (w['address'], float(w['total_txs'] or 0)  ))\n",
    "txs_in  = wallet_transactions.mapValues(lambda w:   w[0] ).filter(lambda w: w[1] is not None)\n",
    "txs_out = wallet_transactions.mapValues(lambda w:   w[1] ).filter(lambda w: w[1] is not None)\n",
    "\n",
    "a_in  = txs_in.flatMapValues(lambda tx: tx.get('inputs',[])).mapValues(lambda tx: tx['address'])\n",
    "a_out = txs_out.flatMapValues(lambda tx: tx.get('outputs',[])).mapValues(lambda tx: tx['address'])\n",
    "\n",
    "v_in  = txs_in.mapValues(lambda w:    float(w['value'] or 0) )\n",
    "v_out = txs_out.mapValues(lambda w:   float(w['value'] or 0) )\n",
    "\n",
    "# features\n",
    "\n",
    "avg_vin = v_in.mapValues(lambda v: (v,1)).reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1] )).mapValues(lambda x: x[0]/x[1])\n",
    "avg_vout =  v_out.mapValues(lambda v: (v,1)).reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1] )).mapValues(lambda x: x[0]/x[1])\n",
    "\n",
    "var_vin = v_in.join(avg_vin).mapValues(lambda v: ((v[0]-v[1])**2,1)).reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1] )).mapValues(lambda x: x[0]/x[1])\n",
    "var_vout =  v_out.join(avg_vout).mapValues(lambda v: ((v[0]-v[1])**2,1)).reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1] )).mapValues(lambda x: x[0]/x[1])\n",
    "\n",
    "unique_deg_in = a_in.mapValues( lambda x: {x}).reduceByKey((lambda a, b: a.union(b))).mapValues(len)\n",
    "unique_deg_out = a_out.mapValues( lambda x: {x}).reduceByKey((lambda a, b: a.union(b))).mapValues(len)\n",
    "\n",
    "deg_in = a_in.mapValues(lambda x: 1).reduceByKey(lambda a, b: a + b)\n",
    "deg_out = a_out.mapValues(lambda x: 1).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# unique_deg_in.collect(), deg_in.collect()\n",
    "v_in.first(), v_out.first()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rdds = [ avg_vin, avg_vout, var_vin, var_vout, unique_deg_in, unique_deg_out, deg_in, deg_out, balance, received_value, total_txs]\n",
    "names = [ 'avg_vin', 'avg_vout', 'var_vin', 'var_vout', 'unique_deg_in', 'unique_deg_out', 'deg_in', 'deg_out', 'balance', 'received_value', 'total_txs']\n",
    "\n",
    "final_df = None\n",
    "for rdd, name in zip(rdds, names):\n",
    "    df = rdd.toDF(['addr', name ])\n",
    "    print(df)\n",
    "    if final_df is None:\n",
    "        final_df = df\n",
    "    else:\n",
    "        final_df = final_df.join(df,'addr', 'outer')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pandas_df = final_df.fillna(0).toPandas()\n",
    "pandas_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from database import *\n",
    "\n",
    "pandas_df.to_sql('wallets_meta', engine,  if_exists='replace', index=False, )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Machine Learning\n",
    "Here there is code for PCA + KMeans"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sklearn.preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "pandas_df = pd.read_sql_table('wallets_meta', engine)\n",
    "\n",
    "data = pandas_df.loc[:, pandas_df.columns != 'addr'].to_numpy()\n",
    "norm_data = sklearn.preprocessing.normalize(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(2)\n",
    "pca = pca.fit(norm_data)\n",
    "grid = pca.transform(norm_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(3)\n",
    "kmeans.fit(norm_data)\n",
    "color_number = kmeans.predict(norm_data)\n",
    "\n",
    "colors = [ ['r','g','b'][i] for i in color_number]\n",
    "print(colors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(*grid.T, c=colors)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}